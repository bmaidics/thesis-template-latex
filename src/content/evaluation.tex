\chapter{Evaluation}
In this thesis, I learned about the Apache Hadoop ecosystem, focusing on Hive and the memory constraints and issues it faces. I went through the lifecycle of a query and identified the main parts of compilation and execution. Using this information I provided measuring points to build a model of the memory usage of HiveServer2. I programmed a code for measuring memory usage automatically and generating heap dumps for later analysis.

\section{Analyzing Heap Dumps}
During my work, I analyzed many heap dumps. The first step to understanding these was to get better insight into the Java memory model and management. The model was not as simple as I first thought. Java distinguishes young and old memory and these are further divided into different parts. I also got to know many tools that I used for analysis to make the detection of memory problems easier. 

\section{Results, Open Issues}
With the measurement tool I created, I was able to detect the phases in which Hive's memory usage increases and investigate the reason behind those. I identified two sources of memory wastage and provided ideas and implementations for fixing those. I also experienced the difficulties of working on a widely used project.

\subsection{HDFS-13752: Path Memory Waste}
One of the issues I identified was the duplication of Strings in HDFS. Although getting rid of the URIs would provide serious memory benefits for Hive and possibly other components, increasing the complexity of such a low-level and ubiquitous part of the platform can have unexpected and unpleasant results. 

However, benchmarking HDFS with and without my patch produced a positive result: no significant CPU overhead can be detected. Still, the community is very wary of the patch, since it touches the very fundamentals of the distributed file system (basically how we store the paths of the files in it), and it is hard to detect the real effects of the change. Currently, Hive performance tests are planned, but gaining access to a larger cluster where benchmarks can be run is proving difficult. In the future, I will work on this issue and try to commit my fix into the Hadoop code base.

\subsection{HIVE-20760: Duplication of HiveConfs}
The other memory issue I found was caused by the presence of multiple and nearly identical configuration objects, which are instances of the class HiveConf. Its configuration values are basically stored in a HashTable. HiveConfs are created regularly in the codebase: for example, every Hive session gets its own configuration. Hive on Spark (HoS) also has about 10\% of memory overhead due to duplicate HiveConfs. 

My idea was to divide the Properties into two parts, so different HiveConfs can use the same "base" if they are identical. This way we can prevent creating different objects with the same content. Implementing my solution saved 40\% memory for every HiveConf. Further testing is needed to cover all scenarios where a configuration object can be used; then, when the patch is ready, the community can review and commit it.

\subsection{Experience Gained }
I learned the basics of working on a huge project like Apache Hive and exploring its codebase as well as debugging errors. Working on an open source project also had many benefits. I gained insight from reviews and feedback provided by far more experienced people around the world. In the future, I plan to continue contributing to Hive and improving one of the most commonly used open-source data warehousing solutions.